#!/usr/bin/env python
# coding: utf-8

import numpy as np
import pandas as pd
import seaborn as sns
from sklearn_extensions.fuzzy_kmeans import FuzzyKMeans
from sklearn.cluster import DBSCAN
from sklearn.decomposition import PCA
from polygone import performance_polygon_vs_player
sns.set()

# need to install kneebow and mlxtend

df = pd.read_csv('../csv/players_stats.csv')
player_names = df["Player"]

clustering_df = df.drop(columns=["Unnamed: 0","Player", "final_team","Pos"])

results = pd.DataFrame(data = None, columns = ['epsilon' , 'min_size', 'score'],dtype=np.float64) 

"""
for var_portion in np.arange(start = 0.6,stop=0.95,step=0.05,dtype=np.float64):
    print(var_portion)
    pca = PCA(n_components=var_portion, svd_solver = 'full')
    pcabis = pca.fit(clustering_df)
    reducedDataSet = pcabis.transform(clustering_df)
    for eps in np.arange(start = 0.05,stop=0.95,step=0.01,dtype=np.float64):
        for size in np.arange(start = 2,stop=10,step=1,dtype=np.float64): 
            m = DBSCAN(eps=eps, min_samples=size)
            m.fit(reducedDataSet)
            if(max(m.labels_)>1):
                score = sklearn.metrics.silhouette_score(clustering_df,m.labels_)
                results = results.append({'var_portion' : var_portion, 'epsilon' : eps , 'min_size' : size , 'score' : score, 'nb_clusters' : max(m.labels_)+1}, ignore_index=True)

results = results.sort_values(by=[ "nb_clusters"], ascending = False)
results.to_csv("../csv/silhouette_search.csv", sep =';')
"""

pca = PCA(n_components=0.85, svd_solver = 'full')
pcabis = pca.fit(clustering_df)
dataSet = pcabis.transform(clustering_df)
model = DBSCAN(eps=0.22, min_samples=2)
model.fit(dataSet)
result = pcabis.inverse_transform(dataSet)
res = np.zeros((0,3))
dbscan_cluster = pd.DataFrame(res)
for k in range(df.shape[0]):
    row = [[df['Player'].values[k], model.labels_[k], df["Pos"].values[k]]]
    dbscan_cluster = dbscan_cluster.append(row)
    #cluster = cluster.sort_values(by=[1], ascending = False)
dbscan_cluster.columns = ["Player", "Cluster", "Pos"]

dbscan_cluster = dbscan_cluster.drop(columns="Pos")

# we save the noise generated by the dbscan 
unclustered_players = pd.DataFrame(dbscan_cluster[dbscan_cluster["Cluster"] == -1])["Player"]

# we remove the noise from the dbscan clusters
dbscan_cluster = dbscan_cluster[dbscan_cluster["Cluster"] != -1]

nb_clusters_from_dbscan = max(dbscan_cluster["Cluster"])

# we keep the interesting value
df_fcm = df[['Player', 'TRB', 'PTS', 'AST', 'DWS', 'TS%', "3PA", "OWS","USG%"]]

# we only keep the unclustered player
df_fcm = pd.merge(df_fcm, unclustered_players, on="Player")

# we keep the players name for later
players_name = df_fcm["Player"]
# we remove the player column for the computation
df_fcm = df_fcm.loc[:,(df_fcm.columns != "Player")]

# Computation
nb_cluster_fuzzy = 5
fuzzy_kmeans = FuzzyKMeans(k=nb_cluster_fuzzy, m=2)
fuzzy_kmeans.fit(df_fcm)
fuzzy_clusters = pd.DataFrame(fuzzy_kmeans.fuzzy_labels_)

# we add the players name back
fuzzy_clusters = pd.concat([players_name, fuzzy_clusters], axis=1)

print("At first we clustered "+str(len(dbscan_cluster.index))+" players")

final_clusters = dbscan_cluster


for i in range(nb_cluster_fuzzy):
    # lets keep the coresponding col of membership degree
    df = fuzzy_clusters[["Player", i]]
    
    # lets sort
    df = df.sort_values(by=i, ascending=False)
    df = df[["Player"]]
    
    #let's juste keep the top n%
    p = 0.05
    proportion_to_keep = round(len(df.index)*p)
    df = df.head(proportion_to_keep)
    print("we add "+str(proportion_to_keep)+" clustered players")
    
    # remove the hard clustered players from the fuzzy df to avoid having duplicates
    fuzzy_clusters = fuzzy_clusters[~fuzzy_clusters['Player'].isin(list(df["Player"]))]
    
    #lets add the # of the cluster
    df["Cluster"] = nb_clusters_from_dbscan+i
    #add those lines to the previous results
    final_clusters = pd.concat([final_clusters, df], axis=0)

print("Now we have "+str(len(final_clusters.index))+" players.")


#now let's print the overlapping polygones for each cluster

nb_totals_cluster = nb_cluster_fuzzy + nb_clusters_from_dbscan

for i in range(int(nb_totals_cluster)):    
    players_to_draw = final_clusters[final_clusters["Cluster"] == i]["Player"].tolist()
    performance_polygon_vs_player(players_to_draw)
    



